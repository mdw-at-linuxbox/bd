---
# Variables listed here are applicable to all host groups

# Can be 'bare' for bare metal, or 'ec2'
deploy_method: 'bare'

# You can override this with a local directory
tarball_dest_path: '/root'

hadoop_version: '2.8.1'
aws_java_sdk_version: '1.10.6'
spark_version: '2.2.0'
presto_version: '0.170'
hive_version: '2.1.1'
maven_version: '3.5.0'

hadoop_binary_name: hadoop-{{ hadoop_version }}.tar.gz
spark_binary_name: spark-{{ spark_version }}-bin-hadoop2.7.tgz
#spark_binary_name: spark-{{ spark_version }}-bin-without-hadoop.tgz
presto_binary_name: presto-server-{{ presto_version }}.tar.gz
presto_cli_name: presto-cli-{{ presto_version }}-executable.jar
hive_binary_name: apache-hive-{{ hive_version }}-bin.tar.gz
maven_binary_name: apache-maven-{{ maven_version }}-bin.tar.gz

# S3 setup
access_key: "{{ lookup('env','AWS_ACCESS_KEY_ID') }}"
secret_key: "{{ lookup('env','AWS_SECRET_ACCESS_KEY') }}"

# Set NTP time server
ntpserver: time.nasa.gov

# S3A Configuration
# Use these to have Hadoop use a Ceph endpoint
s3a_endpoint: 's3.amazonaws.com'           # default 's3.amazonaws.com'
s3a_ssl_enabled: 'true'                    # default true
s3a_path_style_access: 'false'             # default false

# Defaults should be appropriate in Hadoop 2.8.1
s3a_connection_max: 15                     # default 15
s3a_attempts_max: 10                       # default 10
s3a_conn_establish_timeout: 5000           # default 5000
s3a_conn_timeout: 200000                   # default 200000
s3a_page_max: 5000                         # default 5000
s3a_threads_max: 10                        # default 10
s3a_socket_send_buffer: 8192               # default 8192
s3a_socket_recv_buffer: 8192               # default 8192
s3a_keepalive: 60                          # default 60
s3a_max_total_tasks: 5                     # default 5
s3a_multipart_size: '100M'                 # default 100M
s3a_multipart_threshold: 2147483647        # default 2147483647
s3a_multiobjectdelete_enable: 'true'       # default true
s3a_multipart_purge: 'false'               # default false
s3a_multipart_purge_age: 86400             # default 86400

# S3A defaults to AWSv4 signing in Hadoop 2.8.1
# When using a Ceph release before Jewel, set to 'S3SignerType'
# to force AWSv2 signing.
s3a_signing_algorithm: ''                  # default ''

s3a_buffer_dir: '${hadoop.tmp.dir}/s3a'    # default '${hadoop.tmp.dir}/s3a'
s3a_block_size: '32M'                      # default 32M
s3a_user_agent_prefix: ''                  # default ''
s3a_readahead_range: '64K'                 # default '64K'

# S3A with a disk buffer is pretty sane, so we turn it on
s3a_fast_upload: 'true'                    # default 'false'
s3a_fast_upload_buffer: 'disk'             # default 'disk'
s3a_fast_upload_active_blocks: 8           # default 8
s3a_input_fadvise: 'sequential'            # default 'sequential'

s3a_buffer_dir: '/home/s3a'
yarn_local_dirs: '/home'
yarn_app_log_dir: 's3a://app-logs/'

s3a_signing_algorithm: 'S3Signer'

# Hadoop
hadoop_tmp_dir: '/tmp/hadoop-${user.name}' # default '/tmp/hadoop-${user.name}'

# YARN supports S3A buckets for log aggregation in Hadoop 2.8.1.
# This is useful if compute nodes have limited disk capacity.
yarn_nm_remote_app_log_dir: '/tmp/logs'    # default '/tmp/logs'

# Mappers will spill data here, so make sure you have enough capacity
# defaults to  '${hadoop.tmp.dir}/nm-local-dir'
yarn_nm_local_dirs: '${hadoop.tmp.dir}/nm-local-dir'

# Spark
limits_nofile_hard: 65536
limits_nofile_soft: 65536

# Hive
mysql_port: 3306
hive_metastore_database_name: metastore
hive_metastore_mysql_user: hive
hive_metastore_mysql_password: password

hive_metastore_warehouse_dir: s3a://hive/
hive_scratchdir: s3a://tmp/

# Presto
# https://github.com/prestodb/presto/blob/master/presto-hive/src/main/java/com/facebook/presto/hive/HiveS3Config.java
# https://github.com/prestodb/presto/blob/007471c129ef95a794882df6eaa2a8b489884fe0/presto-hive/src/main/java/com/facebook/presto/hive/HiveClientConfig.java
presto_staging_dir: /home/tmp/presto

## Presto 0.170 Tuned setings
#presto_max_conns: 500
#presto_conn_timeout: 5m 
#presto_socket_timeout: 5m 
#presto_max_client_retries: 50 
#presto_max_error_retries: 50 
#presto_max_backoff_times: 10m 
#presto_max_retry_time: 20m 
#presto_metastore_refresh_interval: 1m
#presto_metastore_timeout: 1m
#presto_metastore_cache_ttl: 1m

## Presto 0.170 Default settings
presto_max_conns: 500
presto_conn_timeout: 5s
presto_socket_timeout: 5s
presto_max_retry_time: 10m
presto_max_backoff_times: 10m 
presto_max_client_retries: 3         
presto_max_error_retries: 10         
presto_metastore_timeout: 10s       
presto_metastore_refresh_interval: 0s
presto_metastore_cache_ttl: 0s
presto_max_memory_per_node: 40GB
presto_max_memory_per_cluster: 920GB
presto_jvm_memory: 80G

# Secor
secor_bucket: 'stream'
secor_consumer_threads: 1
secor_max_filesize: 20000000
secor_max_fileage: 60
